{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3679dec",
   "metadata": {},
   "source": [
    "### PCA in Machine Learning Workflows\n",
    "#### Machine Learning I - Maestría en Analítica Aplicada\n",
    "#### Universidad de la Sabana\n",
    "#### Prof: Hugo Franco\n",
    "#### Example: Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c1e1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a6150",
   "metadata": {},
   "source": [
    "The IRIS dataset is used to illustrate the usage of PCA in a Supervised Learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffc6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "# 1. Train baseline k-NN model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Baseline model without PCA\n",
    "start_time = time.time()\n",
    "baseline_model = KNeighborsClassifier(n_neighbors=3)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "baseline_pred = baseline_model.predict(X_test)\n",
    "baseline_time = time.time() - start_time\n",
    "\n",
    "print(\"Baseline Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, baseline_pred):.4f}\")\n",
    "print(f\"Training time: {baseline_time:.4f} seconds\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33fa2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create and train Pipeline with PCA\n",
    "pca_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=2)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=3))\n",
    "])\n",
    "\n",
    "start_time = time.time()\n",
    "pca_pipeline.fit(X_train, y_train)\n",
    "pipeline_pred = pca_pipeline.predict(X_test)\n",
    "pipeline_time = time.time() - start_time\n",
    "\n",
    "print(\"PCA Pipeline Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, pipeline_pred):.4f}\")\n",
    "print(f\"Training time: {pipeline_time:.4f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46343ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Analyze explained variance ratio\n",
    "pca = PCA()\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(range(1, len(cumsum) + 1), cumsum, 'bo-')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.title('Explained Variance vs. Number of Components')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93df8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualize 2D projection\n",
    "pca_2d = PCA(n_components=2)\n",
    "X_2d = pca_2d.fit_transform(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y, cmap='viridis')\n",
    "plt.xlabel(f'First Principal Component')\n",
    "plt.ylabel(f'Second Principal Component')\n",
    "plt.title('Iris Dataset - First Two Principal Components')\n",
    "plt.colorbar(scatter)\n",
    "plt.show()\n",
    "\n",
    "# Print the explained variance ratio for the first two components\n",
    "print(\"Explained variance ratio for first two components:\")\n",
    "print(f\"PC1: {pca_2d.explained_variance_ratio_[0]:.4f}\")\n",
    "print(f\"PC2: {pca_2d.explained_variance_ratio_[1]:.4f}\")\n",
    "print(f\"Total: {sum(pca_2d.explained_variance_ratio_):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c204b84a",
   "metadata": {},
   "source": [
    "#### Class activity - Workshop 3 Challenge: \n",
    "1. Add and organize this example according to the Data Science Workflow\n",
    "2. Apply the workflow to the wine dataset\n",
    "3. Complete the steps in the Supervised Learning Workflow for Data Science according to data preparation and per-model requirements and recommendations in this course, up-to-date\n",
    "4. **Compare the classification performance using the complete set of original features and using only two PCA-transformed features.**\n",
    "5. Modify the example to perform only a binary classification (good > 6) and compare your results with the multiclass performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8751f3c1",
   "metadata": {},
   "source": [
    "##### Wine Dataset Description\n",
    "The Wine Quality dataset contains features like acidity, pH, alcohol content, and quality ratings. We'll convert the quality ratings into a binary classification problem.\n",
    "\n",
    "* Number of instances: 1599\n",
    "* Features: 11 physicochemical properties\n",
    "* Target: Binary (Good/Poor quality) and multiclass (Poor, Fair, and Good quality)\n",
    "* Features include:\n",
    "* Fixed acidity\n",
    "* Volatile acidity\n",
    "* Citric acid\n",
    "* Residual sugar\n",
    "* Chlorides\n",
    "* Free sulfur dioxide\n",
    "* Total sulfur dioxide\n",
    "* Density\n",
    "* pH\n",
    "* Sulphates\n",
    "* Alcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b99ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load wine quality dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "df = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Convert quality scores to three classes\n",
    "def quality_to_class(quality):\n",
    "    if quality <= 5:\n",
    "        return 'poor'\n",
    "    elif quality <= 6:\n",
    "        return 'fair'\n",
    "    else:\n",
    "        return 'good'\n",
    "\n",
    "# Add new column with three classes\n",
    "df['quality_class'] = df['quality'].apply(quality_to_class)\n",
    "\n",
    "# Show distribution of new classes\n",
    "print(\"Three-Class Distribution:\\n\", df['quality_class'].value_counts())\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure()\n",
    "sns.countplot(data=df, x='quality_class', order=['poor', 'fair', 'good'])\n",
    "plt.title('Wine Quality Class Distribution')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
